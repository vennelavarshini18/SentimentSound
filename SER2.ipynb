{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VK1Uxk0disVN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /content/kaggle.json"
      ],
      "metadata": {
        "id": "15-LopQbi4_3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dmitrybabko/speech-emotion-recognition-en\n",
        "!unzip -q speech-emotion-recognition-en.zip -d dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yUzNmc3i6tL",
        "outputId": "d13e616b-61dd-4324-b5e2-c05b98c1455c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/dmitrybabko/speech-emotion-recognition-en\n",
            "License(s): copyright-authors\n",
            "Downloading speech-emotion-recognition-en.zip to /content\n",
            " 95% 938M/987M [00:09<00:00, 107MB/s] \n",
            "100% 987M/987M [00:09<00:00, 108MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa scikit-learn tensorflow numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAxFW0mai9t_",
        "outputId": "d741e8a1-1d1c-485b-8feb-df09fbc00f2f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization)\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "1dytscVVjHwF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/dataset/Crema\"\n",
        "FIXED_LENGTH = 16000\n",
        "SAMPLE_RATE = 16000"
      ],
      "metadata": {
        "id": "gG8-W3veop-0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(y, noise_factor=0.005):\n",
        "    return y + noise_factor * np.random.randn(len(y))\n",
        "\n",
        "def time_stretch(y, rate=0.8):\n",
        "    try:\n",
        "        return librosa.effects.time_stretch(y, rate)\n",
        "    except:\n",
        "        return y\n",
        "\n",
        "def pitch_shift(y, sr, steps=2):\n",
        "    try:\n",
        "        return librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)\n",
        "    except:\n",
        "        return y\n",
        "\n",
        "def extract_features(y, sr=SAMPLE_RATE):\n",
        "    y = librosa.util.fix_length(y, size=FIXED_LENGTH)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64, n_fft=1024, hop_length=256)\n",
        "    log_mel = librosa.power_to_db(mel)\n",
        "    return log_mel\n"
      ],
      "metadata": {
        "id": "gdLBOPIGovIa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(augment=True):\n",
        "    X, y = [], []\n",
        "    emotion_map = {\n",
        "        \"ANG\": \"angry\", \"DIS\": \"disgust\", \"FEA\": \"fear\",\n",
        "        \"HAP\": \"happy\", \"NEU\": \"neutral\", \"SAD\": \"sad\"\n",
        "    }\n",
        "\n",
        "    for file in os.listdir(DATA_PATH):\n",
        "        if not file.endswith(\".wav\"):\n",
        "            continue\n",
        "        try:\n",
        "            parts = file.split(\"_\")\n",
        "            emotion_code = parts[2].strip().upper()\n",
        "            if emotion_code not in emotion_map:\n",
        "                continue\n",
        "            emotion = emotion_map[emotion_code]\n",
        "            path = os.path.join(DATA_PATH, file)\n",
        "            y_raw, sr = librosa.load(path, sr=SAMPLE_RATE, duration=1.0)\n",
        "\n",
        "            for audio in [y_raw,\n",
        "                          add_noise(y_raw),\n",
        "                          pitch_shift(y_raw, sr, steps=2),\n",
        "                          time_stretch(y_raw, rate=0.9)] if augment else [y_raw]:\n",
        "                features = extract_features(audio, sr)\n",
        "                X.append(features)\n",
        "                y.append(emotion)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {file} -> {e}\")\n",
        "            continue\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "SbFL3ePGoy-V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_data(augment=True)\n",
        "X = X[..., np.newaxis]\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, stratify=y_cat, random_state=42)"
      ],
      "metadata": {
        "id": "FmO8Fnkxo1NW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(X.shape[1], X.shape[2], 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(y_cat.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLlGlrRio7a0",
        "outputId": "e33b3702-c6d9-4a8b-ef28-00523b181369"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"best_modelnow.keras\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNS8A2AlobPH",
        "outputId": "2163e3a3-89ec-4202-b49c-b28c2ae6ca99"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2941 - loss: 4.1376\n",
            "Epoch 1: val_accuracy improved from -inf to 0.36580, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - accuracy: 0.2941 - loss: 4.1348 - val_accuracy: 0.3658 - val_loss: 1.5112 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m744/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3694 - loss: 1.4946\n",
            "Epoch 2: val_accuracy improved from 0.36580 to 0.40578, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.3694 - loss: 1.4946 - val_accuracy: 0.4058 - val_loss: 1.4299 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m743/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3940 - loss: 1.4481\n",
            "Epoch 3: val_accuracy improved from 0.40578 to 0.42912, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3940 - loss: 1.4481 - val_accuracy: 0.4291 - val_loss: 1.3948 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m741/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4253 - loss: 1.3896\n",
            "Epoch 4: val_accuracy improved from 0.42912 to 0.44793, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4253 - loss: 1.3896 - val_accuracy: 0.4479 - val_loss: 1.3539 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m736/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4398 - loss: 1.3580\n",
            "Epoch 5: val_accuracy improved from 0.44793 to 0.47313, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4398 - loss: 1.3579 - val_accuracy: 0.4731 - val_loss: 1.3069 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m743/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4671 - loss: 1.3021\n",
            "Epoch 6: val_accuracy improved from 0.47313 to 0.48707, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4671 - loss: 1.3021 - val_accuracy: 0.4871 - val_loss: 1.2734 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m742/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4839 - loss: 1.2690\n",
            "Epoch 7: val_accuracy improved from 0.48707 to 0.51999, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4839 - loss: 1.2689 - val_accuracy: 0.5200 - val_loss: 1.2188 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m743/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5014 - loss: 1.2219\n",
            "Epoch 8: val_accuracy improved from 0.51999 to 0.53342, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5014 - loss: 1.2219 - val_accuracy: 0.5334 - val_loss: 1.1902 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m735/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5206 - loss: 1.1759\n",
            "Epoch 9: val_accuracy improved from 0.53342 to 0.55442, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5206 - loss: 1.1759 - val_accuracy: 0.5544 - val_loss: 1.1316 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m737/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5355 - loss: 1.1431\n",
            "Epoch 10: val_accuracy improved from 0.55442 to 0.58347, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5355 - loss: 1.1431 - val_accuracy: 0.5835 - val_loss: 1.0982 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m741/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5549 - loss: 1.1045\n",
            "Epoch 11: val_accuracy improved from 0.58347 to 0.58818, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5548 - loss: 1.1045 - val_accuracy: 0.5882 - val_loss: 1.0679 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m740/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5604 - loss: 1.0844\n",
            "Epoch 12: val_accuracy improved from 0.58818 to 0.60581, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5604 - loss: 1.0844 - val_accuracy: 0.6058 - val_loss: 1.0311 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m741/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5782 - loss: 1.0489\n",
            "Epoch 13: val_accuracy improved from 0.60581 to 0.61673, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5782 - loss: 1.0489 - val_accuracy: 0.6167 - val_loss: 1.0087 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m742/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5963 - loss: 1.0031\n",
            "Epoch 14: val_accuracy did not improve from 0.61673\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 1.0032 - val_accuracy: 0.6161 - val_loss: 0.9969 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m743/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6078 - loss: 0.9806\n",
            "Epoch 15: val_accuracy improved from 0.61673 to 0.63621, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6078 - loss: 0.9807 - val_accuracy: 0.6362 - val_loss: 0.9495 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m739/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6157 - loss: 0.9647\n",
            "Epoch 16: val_accuracy improved from 0.63621 to 0.64965, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6157 - loss: 0.9648 - val_accuracy: 0.6496 - val_loss: 0.9217 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m742/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6244 - loss: 0.9400\n",
            "Epoch 17: val_accuracy did not improve from 0.64965\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6244 - loss: 0.9400 - val_accuracy: 0.6490 - val_loss: 0.9295 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m743/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6298 - loss: 0.9262\n",
            "Epoch 18: val_accuracy improved from 0.64965 to 0.66275, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6298 - loss: 0.9262 - val_accuracy: 0.6627 - val_loss: 0.8963 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m739/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6414 - loss: 0.9039\n",
            "Epoch 19: val_accuracy improved from 0.66275 to 0.66711, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.6414 - loss: 0.9039 - val_accuracy: 0.6671 - val_loss: 0.8874 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m735/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - loss: 0.8900\n",
            "Epoch 20: val_accuracy improved from 0.66711 to 0.66947, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6445 - loss: 0.8901 - val_accuracy: 0.6695 - val_loss: 0.8627 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m741/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - loss: 0.8813\n",
            "Epoch 21: val_accuracy improved from 0.66947 to 0.67652, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6446 - loss: 0.8814 - val_accuracy: 0.6765 - val_loss: 0.8611 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6559 - loss: 0.8676\n",
            "Epoch 22: val_accuracy improved from 0.67652 to 0.68660, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6559 - loss: 0.8676 - val_accuracy: 0.6866 - val_loss: 0.8414 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m738/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6639 - loss: 0.8378\n",
            "Epoch 23: val_accuracy did not improve from 0.68660\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6638 - loss: 0.8379 - val_accuracy: 0.6743 - val_loss: 0.8418 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m743/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6719 - loss: 0.8275\n",
            "Epoch 24: val_accuracy improved from 0.68660 to 0.70003, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.6719 - loss: 0.8276 - val_accuracy: 0.7000 - val_loss: 0.8081 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6781 - loss: 0.8110\n",
            "Epoch 25: val_accuracy improved from 0.70003 to 0.70087, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6781 - loss: 0.8110 - val_accuracy: 0.7009 - val_loss: 0.8052 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m737/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6862 - loss: 0.8013\n",
            "Epoch 26: val_accuracy improved from 0.70087 to 0.70877, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.6861 - loss: 0.8013 - val_accuracy: 0.7088 - val_loss: 0.8024 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m739/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6879 - loss: 0.8015\n",
            "Epoch 27: val_accuracy improved from 0.70877 to 0.72204, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6879 - loss: 0.8014 - val_accuracy: 0.7220 - val_loss: 0.7711 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m741/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6912 - loss: 0.7795\n",
            "Epoch 28: val_accuracy did not improve from 0.72204\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6912 - loss: 0.7796 - val_accuracy: 0.7183 - val_loss: 0.7683 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m742/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6974 - loss: 0.7694\n",
            "Epoch 29: val_accuracy did not improve from 0.72204\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6974 - loss: 0.7694 - val_accuracy: 0.7183 - val_loss: 0.7725 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m744/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6999 - loss: 0.7607\n",
            "Epoch 30: val_accuracy improved from 0.72204 to 0.72892, saving model to best_model2.keras\n",
            "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6999 - loss: 0.7607 - val_accuracy: 0.7289 - val_loss: 0.7479 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae17c980150>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"label_classes2.npy\", le.classes_)"
      ],
      "metadata": {
        "id": "UD5FoYdeo-HZ"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}